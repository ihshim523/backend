{
  "author": {
    "name": "Pierre Curto"
  },
  "name": "lz4",
  "description": "LZ4 streaming compression and decompression",
  "keywords": [
    "lz4",
    "compression",
    "decompression",
    "stream"
  ],
  "version": "0.3.8",
  "homepage": "http://github.com/pierrec/node-lz4",
  "repository": {
    "type": "git",
    "url": "git://github.com/pierrec/node-lz4.git"
  },
  "main": "./lib/lz4.js",
  "bugs": {
    "url": "http://github.com/pierrec/node-lz4/issues"
  },
  "gypfile": true,
  "licenses": [
    {
      "type": "MIT",
      "url": "http://github.com/pierrec/node-lz4/raw/master/LICENSE"
    }
  ],
  "engines": {
    "node": ">= 0.10"
  },
  "dependencies": {
    "xxhashjs": "latest",
    "cuint": "latest"
  },
  "devDependencies": {
    "benchmark": "*",
    "browserify": ">= 3.x",
    "karma": "^0.12.16",
    "karma-chrome-launcher": "^0.1.3",
    "karma-cli": "~0.0.4",
    "karma-jasmine": "^0.1.5",
    "karma-mocha": "^0.1.3",
    "minify": "latest",
    "mocha": ">= 0.10"
  },
  "scripts": {
    "test": "mocha",
    "install": "node-gyp rebuild",
    "prepublish": "./build.sh"
  },
  "readme": "# LZ4\n\n[LZ4](http://fastcompression.blogspot.fr/) is a very fast compression and decompression algorithm. This nodejs module provides a Javascript implementation of the decoder as well as native bindings to the LZ4 functions. Nodejs Streams are also supported for compression and decompression.\n\nNB.\nVersion 0.2 does not support the legacy format, only the one as of \"LZ4 Streaming Format 1.4\". Use version 0.1 if required.\n\n\n## Install\n\nWith NodeJS:\n\n\tnpm install lz4\n\nWithin the browser, using `build/lz4.js`:\n\n\t<script type=\"text/javascript\" src=\"/path/to/lz4.js\"></script>\n\t<script type=\"text/javascript\">\n\t// Nodejs-like Buffer built-in\n\tvar Buffer = require('buffer').Buffer\n\tvar LZ4 = require('lz4')\n\n\t// Some data to be compressed\n\tvar data = 'Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.'\n\tdata += data\n\t// LZ4 can only work on Buffers\n\tvar input = new Buffer(data)\n\t// Initialize the output buffer to its maximum length based on the input data\n\tvar output = new Buffer( LZ4.encodeBound(input.length) )\n\n\t// block compression (no archive format)\n\tvar compressedSize = LZ4.encodeBlock(input, output)\n\t// remove unnecessary bytes\n\toutput = output.slice(0, compressedSize)\n\n\tconsole.log( \"compressed data\", output.slice(0, compressedSize) )\n\n\t// block decompression (no archive format)\n\tvar uncompressed = new Buffer(input.length)\n\tvar uncompressedSize = LZ4.decodeBlock(output, uncompressed)\n\tuncompressed = uncompressed.slice(0, uncompressedSize)\n\n\tconsole.log( \"uncompressed data\", uncompressed )\n\t</script>\n\nSee below for more LZ4 functions.\n\n\n## Usage\n\n### Encoding\n\nThere are 2 ways to encode:\n\n* __asynchronous__ using nodejs Streams - slowest but can handle very large data sets (no memory limitations).\n* __synchronous__ by feeding the whole set of data - faster but is limited by the amount of memory\n\n\n#### Asynchronous encoding\n\nFirst, create an LZ4 encoding NodeJS stream with `LZ4#createEncoderStream(options)`.\n\n* `options` (_Object_): LZ4 stream options (optional)\n\t* `options.blockMaxSize` (_Number_): chunk size to use (default=4Mb)\n\t* `options.highCompression` (_Boolean_): use high compression (default=false)\n\t* `options.blockIndependence` (_Boolean_): (default=true)\n\t* `options.blockChecksum` (_Boolean_): add compressed blocks checksum (default=false)\n\t* `options.streamSize` (_Boolean_): add full LZ4 stream size (default=false)\n\t* `options.streamChecksum` (_Boolean_): add full LZ4 stream checksum (default=true)\n\t* `options.dict` (_Boolean_): use dictionary (default=false)\n\t* `options.dictId` (_Integer_): dictionary id (default=0)\n\n\nThe stream can then encode any data piped to it. It will emit a `data` event on each encoded chunk, which can be saved into an output stream.\n\nThe following example shows how to encode a file `test` into `test.lz4`.\n\n\n```javascript\nvar fs = require('fs')\nvar lz4 = require('lz4')\n\nvar encoder = lz4.createEncoderStream()\n\nvar input = fs.createReadStream('test')\nvar output = fs.createWriteStream('test.lz4')\n\ninput.pipe(encoder).pipe(output)\n\n```\n\n#### Synchronous encoding\n\nRead the data into memory and feed it to `LZ4#encode(input[, options])` to decode an LZ4 stream.\n\n* `input` (_Buffer_): data to encode\n* `options` (_Object_): LZ4 stream options (optional)\n\t* `options.blockMaxSize` (_Number_): chunk size to use (default=4Mb)\n\t* `options.highCompression` (_Boolean_): use high compression (default=false)\n\t* `options.blockIndependence` (_Boolean_): (default=true)\n\t* `options.blockChecksum` (_Boolean_): add compressed blocks checksum (default=false)\n\t* `options.streamSize` (_Boolean_): add full LZ4 stream size (default=false)\n\t* `options.streamChecksum` (_Boolean_): add full LZ4 stream checksum (default=true)\n\t* `options.dict` (_Boolean_): use dictionary (default=false)\n\t* `options.dictId` (_Integer_): dictionary id (default=0)\n\n\n```javascript\nvar fs = require('fs')\nvar lz4 = require('lz4')\n\nvar input = fs.readFileSync('test')\nvar output = lz4.encode(input)\n\nfs.writeFileSync('test.lz4', output)\n\n```\n\n\n### Decoding\n\nThere are 2 ways to decode:\n\n* __asynchronous__ using nodejs Streams - slowest but can handle very large data sets (no memory limitations)\n* __synchronous__ by feeding the whole LZ4 data - faster but is limited by the amount of memory\n\n\n#### Asynchronous decoding\n\nFirst, create an LZ4 decoding NodeJS stream with `LZ4#createDecoderStream()`.\n\n\nThe stream can then decode any data piped to it. It will emit a `data` event on each decoded sequence, which can be saved into an output stream.\n\nThe following example shows how to decode an LZ4 compressed file `test.lz4` into `test`.\n\n\n```javascript\nvar fs = require('fs')\nvar lz4 = require('lz4')\n\nvar decoder = lz4.createDecoderStream()\n\nvar input = fs.createReadStream('test.lz4')\nvar output = fs.createWriteStream('test')\n\ninput.pipe(decoder).pipe(output)\n\n```\n\n#### Synchronous decoding\n\nRead the data into memory and feed it to `LZ4#decode(input)` to produce an LZ4 stream.\n\n* `input` (_Buffer_): data to decode\n\n\n```javascript\nvar fs = require('fs')\nvar lz4 = require('lz4')\n\nvar input = fs.readFileSync('test.lz4')\nvar output = lz4.decode(input)\n\nfs.writeFileSync('test', output)\n\n```\n\n## Block level encoding/decoding\n\nIn some cases, it is useful to be able to manipulate an LZ4 block instead of an LZ4 stream. The functions to decode and encode are therefore exposed as:\n\n* `LZ4#decodeBlock(input, output)` (_Number_) >=0: uncompressed size, <0: error at offset\n\t* `input` (_Buffer_): data block to decode\n\t* `output` (_Buffer_): decoded data block\n* `LZ4#encodeBound(inputSize)` (_Number_): maximum size for a compressed block\n\t* `inputSize` (_Number_) size of the input, 0 if too large\n\tThis is required to size the buffer for a block encoded data\n* `LZ4#encodeBlock(input, output)` (_Number_) >0: compressed size, =0: not compressible\n\t* `input` (_Buffer_): data block to encode\n\t* `output` (_Buffer_): encoded data block\n* `LZ4#encodeBlockHC(input, output)` (_Number_) >0: compressed size, =0: not compressible\n\t* `input` (_Buffer_): data block to encode with high compression\n\t* `output` (_Buffer_): encoded data block\n\n\nBlocks do not have any magic number and are provided as is. It is useful to store somewhere the size of the original input for decoding.\nLZ4#encodeBlockHC() is not available as pure Javascript.\n\n\n## How it works\n\n* [LZ4 stream format](http://fastcompression.blogspot.fr/2011/05/lz4-explained.html)\n\n## Restrictions / Issues\n\n* `blockIndependence` property only supported for `true`\n\n\n## License\n\nMIT",
  "readmeFilename": "README.md",
  "_id": "lz4@0.3.8",
  "dist": {
    "shasum": "dbaa0793f43792ccf6b1384495d7cf1308064de3"
  },
  "_from": "lz4@",
  "_resolved": "https://registry.npmjs.org/lz4/-/lz4-0.3.8.tgz"
}
